1. Regression Algorithms
These algorithms predict continuous outputs.
Linear Regression: Used to predict a continuous value based on one or more features.
Multi-Linear Regression: Extends linear regression to multiple features.
Polynomial Regression: Models non-linear relationships using polynomial features.

2. Supervised Learning (Regression and Classification)
Logistic Regression: Despite its name, this is a classification algorithm used to predict categorical outcomes (0/1, True/False).
K-Nearest Neighbors (KNN): Primarily used for classification but can also be used for regression by averaging the output values of neighbors.
Support Vector Machine (SVM): Works for both classification and regression (Support Vector Regression, SVR).
Random Forest: Used for both regression and classification by building multiple decision trees.
Adaboost & XGBoost: Boosting algorithms for classification and regression tasks.

3. Unsupervised Learning (Clustering and Association)
Principal Component Analysis (PCA): Mainly used for dimensionality reduction, a preprocessing step in unsupervised learning.
Singular Value Decomposition (SVD): Also used for dimensionality reduction and matrix factorization.
Clustering:
K-Means: A common clustering algorithm that groups similar data points together.
Hierarchical Clustering: Builds a hierarchy of clusters.
Association Rule Learning:
Apriori Algorithm: Used to find associations and relationships between different items in large datasets (e.g., market basket analysis).
Eclat Algorithm: Another association rule algorithm used for finding frequent item sets.
